#  NaÃ¯ve Bayes, Boosting & Decision Boundaries

##  Project Overview
This project investigates **NaÃ¯ve Bayes classification**, **Boosting**, and **Decision Tree ensembles** for improving classification accuracy. It evaluates the **bias-variance tradeoff**, the effect of boosting iterations, and training data splits on **Iris and Vowel datasets**.

##  Technologies & Tools Used
- **Programming Language**: Python
- **Libraries**: NumPy, Matplotlib, Scikit-learn
- **Algorithms**: NaÃ¯ve Bayes, Decision Trees, AdaBoost
- **Evaluation Metrics**: Classification Accuracy, Decision Boundaries, Model Complexity

## ğŸ” Key Features
### **ğŸ“Š NaÃ¯ve Bayes & Feature Independence**
- **Analyzed feature independence assumptions** in the Iris dataset.
- **Explored decision boundary limitations** in linear models.
- **Compared different feature transformations** to improve separability.

### **âš¡ Boosting for Classification Improvement**
- **Implemented AdaBoost** on NaÃ¯ve Bayes & Decision Trees.
- **Tracked accuracy improvement** over boosting iterations.
- **Plotted decision boundary evolution** before and after boosting.

### **ğŸ“ˆ Training Data Split & Model Generalization**
- **Tested different training data proportions** to assess learning stability.
- **Evaluated overfitting risks** in boosted models.
- **Compared classifier performance (SVM, KNN, Random Forests)** on multiple datasets.

## ğŸ“Š Results
âœ”ï¸ **Boosting significantly improves accuracy**, especially for complex datasets.  
âœ”ï¸ **NaÃ¯ve Bayes is effective but limited by feature independence assumptions**.  
âœ”ï¸ **Decision Trees benefit from boosting**, but require **pruning** to prevent overfitting.  
âœ”ï¸ **Training data splits impact performance**, with 30%-60% offering optimal results.  

## ğŸ”„ Future Improvements
- Implement **Gradient Boosting (XGBoost)** for improved ensemble learning.
- Apply **Feature Selection Methods** to enhance model interpretability.
- Extend experiments to **imbalanced datasets** to assess classifier robustness.

---
